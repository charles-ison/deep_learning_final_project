Epoch 1:   0%|          | 0/5 [00:00<?, ?steps/s]Epoch 1:  20%|██        | 1/5 [01:02<04:09, 62.37s/steps]Epoch 1:  40%|████      | 2/5 [01:59<02:58, 59.49s/steps]Epoch 1:  60%|██████    | 3/5 [02:55<01:55, 57.62s/steps]Epoch 1:  80%|████████  | 4/5 [03:50<00:56, 56.72s/steps]Traceback (most recent call last):
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/train_model.py", line 105, in <module>
    predicted_codes = model(mem, tgt, tgt_mask=batch_tgt_mask)  # [B, L, Q, V]
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 89, in parallel_apply
    output.reraise()
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/modules/audio_transformer_decoder.py", line 39, in forward
    transformer_output = self.transformer_decoder(tgt, mem, tgt_mask)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 369, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 712, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask, tgt_is_causal)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 725, in _sa_block
    x = self.self_attn(x, x, x,
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1205, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/nfs/hpc/share/stemgen/jcmain/deep_learning_final_project/env/lib/python3.10/site-packages/torch/nn/functional.py", line 5256, in multi_head_attention_forward
    raise RuntimeError(f"The shape of the 3D attn_mask is {attn_mask.shape}, but should be {correct_3d_size}.")
RuntimeError: The shape of the 3D attn_mask is torch.Size([46, 375, 375]), but should be (48, 375, 375).

Epoch 1:  80%|████████  | 4/5 [04:07<01:01, 61.99s/steps]
