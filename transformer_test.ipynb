{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dl19Asqk79-G"
      },
      "outputs": [],
      "source": [
        "!pip -qqq install transformers datasets nnAudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KFbW0b6v7uAX"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchaudio.transforms as T\n",
        "from datasets import Dataset, Audio, concatenate_datasets, Split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXOmbPCXPgTP",
        "outputId": "241b6aab-ac27-426d-f797-f887b252c25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount drive and set path to dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/Shareddrives/DeepLearningProject/minibabyslakh\"\n",
        "# make sure \n",
        "os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pxhU5aIY8KRL"
      },
      "outputs": [],
      "source": [
        "# loading our model weights\n",
        "model = AutoModel.from_pretrained(\"m-a-p/MERT-v0\", trust_remote_code=True)\n",
        "# loading the corresponding preprocessor config\n",
        "processor = Wav2Vec2FeatureExtractor.from_pretrained(\"m-a-p/MERT-v0\",trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "guN3LtRXYhuk"
      },
      "outputs": [],
      "source": [
        "# # load demo audio and set processor\n",
        "# dataset = Dataset.load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
        "# dataset = dataset.sort(\"id\")\n",
        "# sampling_rate = dataset.features[\"audio\"].sampling_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-SCGvvx9JHtw"
      },
      "outputs": [],
      "source": [
        "# Function to load the audio files from the directory structure\n",
        "def get_data_files(directory):\n",
        "    bass_files = []\n",
        "    residual_files = []\n",
        "    tracks = []\n",
        "    for track_dir in os.listdir(directory):\n",
        "        track_path = os.path.join(directory, track_dir)\n",
        "        if os.path.isdir(track_path):\n",
        "            bass_audio_dir = os.path.join(track_path, 'bass')\n",
        "            # bass_file = os.path.join(bass_audio_dir, 'bass.wav')\n",
        "            # residual_file = os.path.join(bass_audio_dir, 'residuals.wav')\n",
        "            if os.path.isdir(bass_audio_dir):\n",
        "                for file in os.listdir(bass_audio_dir):\n",
        "                    if file.startswith('bass') and file.endswith('.wav'):\n",
        "                        bass_file = os.path.join(bass_audio_dir, file)\n",
        "                        bass_files.append(bass_file)\n",
        "                        residual_file = os.path.join(bass_audio_dir, 'residuals' + file[4:])\n",
        "                        residual_files.append(residual_file)\n",
        "                        tracks.append(track_dir)\n",
        "        \n",
        "    return {\"bass\": bass_files, \"residuals\": residual_files, \"track\": tracks}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0rXcxIlS1yK",
        "outputId": "cd2eddfd-4bfd-420d-834b-ef1d3591aac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bass': ['/content/drive/Shareddrives/DeepLearningProject/minibabyslakh/train/Track00002/bass/bass.wav',\n",
              "  '/content/drive/Shareddrives/DeepLearningProject/minibabyslakh/train/Track00001/bass/bass.wav',\n",
              "  '/content/drive/Shareddrives/DeepLearningProject/minibabyslakh/train/Track00003/bass/bass.wav'],\n",
              " 'residuals': ['/content/drive/Shareddrives/DeepLearningProject/minibabyslakh/train/Track00002/bass/residuals.wav',\n",
              "  '/content/drive/Shareddrives/DeepLearningProject/minibabyslakh/train/Track00001/bass/residuals.wav',\n",
              "  '/content/drive/Shareddrives/DeepLearningProject/minibabyslakh/train/Track00003/bass/residuals.wav'],\n",
              " 'track': ['Track00002', 'Track00001', 'Track00003']}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Get the audio filenames from the dataset directory\n",
        "train_files = get_data_files(os.path.join(data_dir, \"train\"))\n",
        "test_files = get_data_files(os.path.join(data_dir, \"test\"))\n",
        "# validation_data = load_audio_files(os.path.join(data_dir, \"validation\"))\n",
        "train_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4tfjuUfYpCV",
        "outputId": "441c395e-b383-41ce-d2e8-d111f9b2201c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['bass', 'residuals', 'track'],\n",
              "    num_rows: 3\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Create the dataset objects\n",
        "train_dataset = Dataset.from_dict(train_files, split=\"train\") \\\n",
        "                    .cast_column(\"bass\", Audio()) \\\n",
        "                    .cast_column(\"residuals\", Audio()) \\\n",
        "                    .sort(\"track\")\n",
        "test_dataset = Dataset.from_dict(test_files, split=\"test\") \\\n",
        "                    .cast_column(\"bass\", Audio()) \\\n",
        "                    .cast_column(\"residuals\", Audio()) \\\n",
        "                    .sort(\"track\")\n",
        "combined_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
        "\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3kxvhTbB-IKA"
      },
      "outputs": [],
      "source": [
        "sampling_rate = train_dataset[\"residuals\"][0]['sampling_rate']\n",
        "resample_rate = processor.sampling_rate\n",
        "# make sure the sample_rate aligned\n",
        "if resample_rate != sampling_rate:\n",
        "    print(f'setting rate from {sampling_rate} to {resample_rate}')\n",
        "    resampler = T.Resample(sampling_rate, resample_rate)\n",
        "else:\n",
        "    resampler = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KIn1GRQa-wx-"
      },
      "outputs": [],
      "source": [
        "# audio file is decoded on the fly\n",
        "if resampler is None:\n",
        "    src_audio = train_dataset[0][\"residuals\"][\"array\"]\n",
        "    tgt_audio = train_dataset[0][\"bass\"][\"array\"]\n",
        "else:\n",
        "  src_audio = resampler(torch.from_numpy(train_dataset[0][\"residuals\"][\"array\"]))\n",
        "  tgt_audio = resampler(torch.from_numpy(train_dataset[0][\"bass\"][\"array\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cjrxz_BYiYiN"
      },
      "outputs": [],
      "source": [
        "# The whole audio file is too big to run in colab\n",
        "src_audio = src_audio[0:50000]\n",
        "tgt_audio = tgt_audio[0:50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "phYaHnl-_BRc"
      },
      "outputs": [],
      "source": [
        "src_inputs = processor(src_audio, sampling_rate=resample_rate, return_tensors=\"pt\")\n",
        "tgt_inputs = processor(tgt_audio, sampling_rate=resample_rate, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    src_outputs = model(**src_inputs, output_hidden_states=True)\n",
        "    tgt_outputs = model(**tgt_inputs, output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhaB1K8-iJXR",
        "outputId": "bfc165b2-3f66-4e29-afd1-c1ab253f268b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_hidden_states.shape: torch.Size([13, 156, 768])\n",
            "tgt_hidden_states.shape: torch.Size([13, 156, 768])\n"
          ]
        }
      ],
      "source": [
        "# take a look at the output shape, there are 13 layers of representation\n",
        "# each layer performs differently in different downstream tasks, you should choose empirically\n",
        "src_hidden_states = torch.stack(src_outputs.hidden_states).squeeze()\n",
        "tgt_hidden_states = torch.stack(tgt_outputs.hidden_states).squeeze()\n",
        "\n",
        "print(\"src_hidden_states.shape: \" + str(src_hidden_states.shape))\n",
        "print(\"tgt_hidden_states.shape: \" + str(tgt_hidden_states.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Model"
      ],
      "metadata": {
        "id": "7nHJRvijLxVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = src_hidden_states.size(dim = 1)\n",
        "d_model = src_hidden_states.size(dim = 2)\n",
        "\n",
        "#TODO: Change the hyperparameters and consider custom implementations once we get something working\n",
        "transformer_decoder_layer = nn.TransformerDecoderLayer(d_model = 2 * d_model, nhead = 8)\n",
        "transformer_decoder = nn.TransformerDecoder(transformer_decoder_layer, num_layers = 6)\n",
        "\n",
        "print(transformer_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSn9CPlMBcVH",
        "outputId": "86bae804-de8c-4da1-c3b3-8104dc76e3b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerDecoder(\n",
            "  (layers): ModuleList(\n",
            "    (0-5): 6 x TransformerDecoderLayer(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1536, out_features=1536, bias=True)\n",
            "      )\n",
            "      (multihead_attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1536, out_features=1536, bias=True)\n",
            "      )\n",
            "      (linear1): Linear(in_features=1536, out_features=2048, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (linear2): Linear(in_features=2048, out_features=1536, bias=True)\n",
            "      (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (dropout3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "9eJULPtnL0r_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj0xTETLpxtx",
        "outputId": "7b1b6d0d-8dc7-4a0b-d4b1-58077291ce6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating token: 0/156\n",
            "Generating token: 1/156\n",
            "Generating token: 2/156\n",
            "Generating token: 3/156\n",
            "Generating token: 4/156\n",
            "Generating token: 5/156\n",
            "Generating token: 6/156\n",
            "Generating token: 7/156\n",
            "Generating token: 8/156\n",
            "Generating token: 9/156\n",
            "Generating token: 10/156\n",
            "Generating token: 11/156\n",
            "Generating token: 12/156\n",
            "Generating token: 13/156\n",
            "Generating token: 14/156\n",
            "Generating token: 15/156\n",
            "Generating token: 16/156\n",
            "Generating token: 17/156\n",
            "Generating token: 18/156\n",
            "Generating token: 19/156\n",
            "Generating token: 20/156\n",
            "Generating token: 21/156\n",
            "Generating token: 22/156\n",
            "Generating token: 23/156\n",
            "Generating token: 24/156\n",
            "Generating token: 25/156\n",
            "Generating token: 26/156\n",
            "Generating token: 27/156\n",
            "Generating token: 28/156\n",
            "Generating token: 29/156\n",
            "Generating token: 30/156\n",
            "Generating token: 31/156\n",
            "Generating token: 32/156\n",
            "Generating token: 33/156\n",
            "Generating token: 34/156\n",
            "Generating token: 35/156\n",
            "Generating token: 36/156\n",
            "Generating token: 37/156\n",
            "Generating token: 38/156\n",
            "Generating token: 39/156\n",
            "Generating token: 40/156\n",
            "Generating token: 41/156\n",
            "Generating token: 42/156\n",
            "Generating token: 43/156\n",
            "Generating token: 44/156\n",
            "Generating token: 45/156\n",
            "Generating token: 46/156\n",
            "Generating token: 47/156\n",
            "Generating token: 48/156\n",
            "Generating token: 49/156\n",
            "Generating token: 50/156\n",
            "Generating token: 51/156\n",
            "Generating token: 52/156\n",
            "Generating token: 53/156\n",
            "Generating token: 54/156\n",
            "Generating token: 55/156\n",
            "Generating token: 56/156\n",
            "Generating token: 57/156\n",
            "Generating token: 58/156\n",
            "Generating token: 59/156\n",
            "Generating token: 60/156\n",
            "Generating token: 61/156\n",
            "Generating token: 62/156\n",
            "Generating token: 63/156\n",
            "Generating token: 64/156\n",
            "Generating token: 65/156\n",
            "Generating token: 66/156\n",
            "Generating token: 67/156\n",
            "Generating token: 68/156\n",
            "Generating token: 69/156\n",
            "Generating token: 70/156\n",
            "Generating token: 71/156\n",
            "Generating token: 72/156\n",
            "Generating token: 73/156\n",
            "Generating token: 74/156\n",
            "Generating token: 75/156\n",
            "Generating token: 76/156\n",
            "Generating token: 77/156\n",
            "Generating token: 78/156\n",
            "Generating token: 79/156\n",
            "Generating token: 80/156\n",
            "Generating token: 81/156\n",
            "Generating token: 82/156\n",
            "Generating token: 83/156\n",
            "Generating token: 84/156\n",
            "Generating token: 85/156\n",
            "Generating token: 86/156\n",
            "Generating token: 87/156\n",
            "Generating token: 88/156\n",
            "Generating token: 89/156\n",
            "Generating token: 90/156\n",
            "Generating token: 91/156\n",
            "Generating token: 92/156\n",
            "Generating token: 93/156\n",
            "Generating token: 94/156\n",
            "Generating token: 95/156\n",
            "Generating token: 96/156\n",
            "Generating token: 97/156\n",
            "Generating token: 98/156\n",
            "Generating token: 99/156\n",
            "Generating token: 100/156\n",
            "Generating token: 101/156\n",
            "Generating token: 102/156\n",
            "Generating token: 103/156\n",
            "Generating token: 104/156\n",
            "Generating token: 105/156\n",
            "Generating token: 106/156\n",
            "Generating token: 107/156\n",
            "Generating token: 108/156\n",
            "Generating token: 109/156\n",
            "Generating token: 110/156\n",
            "Generating token: 111/156\n",
            "Generating token: 112/156\n",
            "Generating token: 113/156\n",
            "Generating token: 114/156\n",
            "Generating token: 115/156\n",
            "Generating token: 116/156\n",
            "Generating token: 117/156\n",
            "Generating token: 118/156\n",
            "Generating token: 119/156\n",
            "Generating token: 120/156\n",
            "Generating token: 121/156\n",
            "Generating token: 122/156\n",
            "Generating token: 123/156\n",
            "Generating token: 124/156\n",
            "Generating token: 125/156\n",
            "Generating token: 126/156\n",
            "Generating token: 127/156\n",
            "Generating token: 128/156\n",
            "Generating token: 129/156\n",
            "Generating token: 130/156\n",
            "Generating token: 131/156\n",
            "Generating token: 132/156\n",
            "Generating token: 133/156\n",
            "Generating token: 134/156\n",
            "Generating token: 135/156\n",
            "Generating token: 136/156\n",
            "Generating token: 137/156\n",
            "Generating token: 138/156\n",
            "Generating token: 139/156\n",
            "Generating token: 140/156\n",
            "Generating token: 141/156\n",
            "Generating token: 142/156\n",
            "Generating token: 143/156\n",
            "Generating token: 144/156\n",
            "Generating token: 145/156\n",
            "Generating token: 146/156\n",
            "Generating token: 147/156\n",
            "Generating token: 148/156\n",
            "Generating token: 149/156\n",
            "Generating token: 150/156\n",
            "Generating token: 151/156\n",
            "Generating token: 152/156\n",
            "Generating token: 153/156\n",
            "Generating token: 154/156\n",
            "Generating token: 155/156\n",
            "Generated tokens: [tensor([[ 2.5530, -0.0095,  0.1963,  ...,  1.4309, -0.4729,  1.3494]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.2623, -0.1842,  0.2156,  ...,  2.0219, -0.3491,  1.4175]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.1752, -0.1486,  0.0380,  ...,  2.2129, -0.0525,  1.3402]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.6465, -0.1199, -0.2219,  ...,  2.0123,  0.2652,  1.4451]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.5817,  0.6746, -0.1144,  ...,  2.2423, -0.1834,  1.1033]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.5533,  0.9837,  0.6711,  ...,  2.1989, -0.7160,  1.1068]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8261, 1.4651, 0.7204,  ..., 2.6047, 0.2992, 1.1286]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.3083, 0.9687, 0.5299,  ..., 2.8589, 0.8174, 0.8201]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5176, 0.9538, 0.5962,  ..., 2.9679, 0.6265, 0.8676]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.9995, 1.0165, 0.4898,  ..., 2.3636, 0.1814, 1.6667]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.9604, 1.1672, 0.7000,  ..., 2.2903, 0.6979, 1.2718]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1479, 0.9327, 0.5289,  ..., 2.8330, 0.5401, 1.4431]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.5630, 1.3444, 1.3095,  ..., 1.9678, 0.5707, 0.7867]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.6335, 0.9520, 1.3637,  ..., 1.9232, 0.7656, 0.6856]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.3029, 0.3471, 1.5909,  ..., 2.2686, 0.5809, 1.1616]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7821, 1.1391, 0.9929,  ..., 2.5905, 1.0146, 2.0420]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5916, 1.3642, 0.6207,  ..., 2.2360, 0.8209, 1.3356]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1334, 0.9009, 0.7747,  ..., 2.3117, 0.6323, 1.4529]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.2271, 0.5295, 0.5127,  ..., 2.0742, 0.8495, 1.6933]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0394, 0.6400, 0.3917,  ..., 1.8408, 0.3770, 1.8759]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.5751,  1.5150,  0.0926,  ...,  1.9426, -0.1694,  1.6213]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.3482,  1.2465, -0.0727,  ...,  1.9260,  0.0790,  2.1021]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.3395, 0.4856, 0.7575,  ..., 2.3587, 0.7181, 1.6259]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.5555, 0.2028, 0.8524,  ..., 2.5200, 0.9275, 2.0658]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5316, 1.1073, 0.7404,  ..., 2.6468, 0.5993, 1.8818]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0911, 1.3747, 0.6801,  ..., 2.1551, 0.2524, 1.6071]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.6886,  1.1659,  0.7103,  ...,  2.2189, -0.2582,  1.7590]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.6183, 0.7556, 0.9313,  ..., 1.5304, 0.4329, 1.2087]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.6763, 0.1001, 1.1131,  ..., 2.0590, 0.2416, 0.8914]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.1896, 0.6787, 1.6048,  ..., 2.1211, 0.2770, 1.2511]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.1697, 1.2139, 0.8238,  ..., 1.3528, 0.4915, 1.5143]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4094, 0.8180, 0.9330,  ..., 1.6143, 0.6689, 1.5453]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1118, 0.6930, 0.6730,  ..., 1.8360, 0.5996, 1.6348]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7964, 1.1083, 0.9796,  ..., 2.0013, 0.5151, 1.5374]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4913, 0.7490, 1.5471,  ..., 2.6602, 0.3241, 1.1943]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[0.9647, 1.2811, 0.9799,  ..., 3.0293, 0.1965, 1.2698]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.2031,  0.9727,  0.2545,  ...,  2.3545, -0.2973,  0.9602]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.3224,  0.7573,  0.3527,  ...,  1.9558, -0.1209,  0.6769]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.6636,  1.2487,  0.5230,  ...,  2.2841, -0.2300,  1.6792]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.1823,  1.1557,  0.7135,  ...,  2.5752, -0.2370,  1.8457]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4497, 0.7621, 0.8754,  ..., 1.5101, 0.0217, 1.0303]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8633, 1.0338, 0.1393,  ..., 2.0104, 0.0769, 1.3301]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.7166,  0.6247, -0.0840,  ...,  2.2687,  0.3337,  1.3613]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.4441,  0.8915, -0.4129,  ...,  1.8936, -0.1237,  1.0629]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.5269, 1.6963, 0.2917,  ..., 2.4666, 0.4134, 2.0718]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.4136, 1.5597, 0.6721,  ..., 2.7829, 0.4685, 1.9113]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8973, 0.8883, 0.8176,  ..., 2.5239, 1.0014, 1.5547]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7367, 1.6157, 1.1109,  ..., 1.9430, 1.0231, 1.3559]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1527, 1.7267, 0.9367,  ..., 2.2007, 0.9033, 1.4197]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0729, 1.6292, 0.3390,  ..., 2.4553, 0.7499, 1.6107]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1571, 0.6490, 0.4203,  ..., 2.7619, 0.6157, 2.4566]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.3624, 1.2302, 0.4839,  ..., 2.4192, 0.3232, 2.1213]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.3727,  0.8549, -0.1201,  ...,  1.8292,  0.7987,  1.4997]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7201, 0.4973, 0.2223,  ..., 1.4792, 0.9300, 1.0774]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.9076, 0.5073, 0.8265,  ..., 2.5114, 0.9002, 1.1394]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[0.7868, 0.6210, 0.7203,  ..., 2.2365, 0.9898, 1.4738]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.5534, 0.8921, 0.7105,  ..., 2.7378, 0.4966, 1.3414]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7947, 1.6110, 0.7979,  ..., 2.2446, 0.3702, 1.6970]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4842, 1.3901, 0.6027,  ..., 1.7732, 0.4584, 1.1496]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.0408, 0.5215, 0.8322,  ..., 2.4459, 0.3069, 1.6698]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.2732, 0.5652, 0.9338,  ..., 2.9645, 0.5216, 1.1134]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5666, 0.7319, 0.5559,  ..., 2.6918, 0.1072, 0.6328]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[0.8154, 0.5594, 0.5781,  ..., 1.8423, 0.5655, 0.6257]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7977, 0.7261, 0.9164,  ..., 2.3991, 0.5123, 0.9829]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5231, 0.9911, 1.2705,  ..., 2.7642, 0.9660, 1.0718]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[0.9703, 0.7300, 0.7765,  ..., 2.1091, 0.2375, 0.8467]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[0.9031, 0.9851, 1.3046,  ..., 1.8755, 0.2666, 1.1291]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.6555, 1.2129, 0.9175,  ..., 1.9598, 0.6021, 1.0210]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.4352,  0.8243,  0.8485,  ...,  1.5037, -0.0514,  0.7469]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1401, 0.8587, 1.2817,  ..., 1.6960, 0.2093, 1.4151]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5330, 0.1216, 0.8732,  ..., 2.4784, 0.3328, 1.7671]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.1456, 0.8637, 1.2469,  ..., 1.8654, 0.1285, 0.8996]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.6684, 0.9940, 0.5688,  ..., 2.0640, 0.2442, 1.3337]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.2915, 0.8684, 0.3923,  ..., 2.3373, 1.0462, 1.4924]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7076, 1.5519, 0.5834,  ..., 1.9326, 1.3134, 1.6898]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7909, 1.1677, 1.2578,  ..., 2.5177, 1.2483, 1.9366]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.2278, 1.3998, 2.1535,  ..., 2.4760, 0.8964, 2.0242]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8587, 0.7381, 1.4611,  ..., 2.5559, 0.4887, 1.6414]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1925, 0.4883, 0.6112,  ..., 2.9183, 0.0547, 1.1876]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7953, 0.2092, 0.5158,  ..., 2.1221, 0.5688, 1.0278]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4362, 0.5417, 0.3367,  ..., 1.4440, 0.1122, 1.5945]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4559, 0.5624, 0.3299,  ..., 1.7692, 0.4119, 1.5346]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1552, 0.7017, 0.2290,  ..., 2.2106, 0.4219, 1.6610]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0961, 0.7035, 0.6472,  ..., 2.8448, 1.3982, 1.8395]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.6077, 0.9195, 0.8409,  ..., 1.6347, 1.0772, 1.5770]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4539, 0.6719, 1.1087,  ..., 2.1247, 0.6963, 1.2625]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7472, 0.2040, 0.7743,  ..., 2.4885, 0.7142, 1.6474]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0172, 0.5208, 0.6220,  ..., 1.8065, 0.5657, 1.4290]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.1516,  0.8308,  0.8792,  ...,  1.9949, -0.0861,  1.5638]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.2706,  0.5126,  1.0405,  ...,  1.9722, -0.4361,  1.1706]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7534, 0.5847, 0.9013,  ..., 1.8737, 0.0668, 1.0526]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.0143,  0.9027,  0.8471,  ...,  2.6320, -0.0307,  1.5748]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.9492, 1.1383, 0.9297,  ..., 2.3879, 0.2920, 1.8251]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.1864,  0.9817,  0.7609,  ...,  2.1352, -0.2252,  1.3925]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8520, 0.0411, 0.3205,  ..., 2.5714, 0.3345, 1.3010]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.8110,  0.0857,  0.6479,  ...,  1.9673, -0.0173,  0.7916]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0570, 0.8095, 0.2139,  ..., 1.8120, 0.1730, 1.5443]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.5495,  1.4184,  0.8000,  ...,  1.5733, -0.1674,  1.2009]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.4731,  1.6460,  0.3392,  ...,  2.3255, -0.1658,  0.9320]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.1588,  1.4376,  0.3051,  ...,  2.0923, -0.5537,  1.3540]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.8547,  1.1108,  0.3974,  ...,  2.1735, -0.8058,  1.3269]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7251, 1.0775, 0.0953,  ..., 1.9092, 0.2381, 1.3253]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.7504,  0.3021,  0.6981,  ...,  2.7150, -0.4524,  1.6379]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.0757,  0.7666, -0.2067,  ...,  2.4400,  0.0794,  1.4452]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.3739,  1.6335,  0.0483,  ...,  2.2365, -0.1657,  1.7470]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.4322, 1.6033, 0.9846,  ..., 2.2237, 0.1513, 1.2625]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.4097, 1.6701, 0.1359,  ..., 2.2226, 0.2871, 1.4354]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5873, 0.9619, 0.5260,  ..., 2.1773, 0.4223, 1.1634]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.1325, 1.0465, 0.4241,  ..., 1.8114, 0.4697, 1.4703]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7099, 0.8650, 0.6687,  ..., 1.9695, 0.6869, 1.2228]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8402, 0.9049, 1.6601,  ..., 2.7698, 0.4131, 1.1175]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.6576,  0.8095,  0.6110,  ...,  2.1537, -0.1805,  1.1763]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7709, 1.3794, 1.2085,  ..., 1.4691, 0.4479, 1.0905]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.0675,  0.7575,  0.5526,  ...,  1.8799, -0.4139,  1.5475]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1942, 1.2046, 0.7528,  ..., 1.8684, 0.5495, 1.5440]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0506, 0.9171, 0.9903,  ..., 2.3406, 0.7439, 1.7650]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1744, 0.9687, 0.4678,  ..., 1.9459, 0.2257, 1.2852]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.9898, 0.5149, 1.1422,  ..., 2.1639, 0.4415, 0.9395]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5879, 0.6094, 0.3051,  ..., 1.9149, 0.3283, 1.1795]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.2794, 0.7688, 0.5872,  ..., 1.7689, 0.6045, 1.2370]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.9152, 0.6717, 0.6931,  ..., 1.4740, 0.4720, 1.1743]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1861, 0.9444, 1.0621,  ..., 1.6771, 0.8621, 1.5218]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1466, 0.6462, 1.3749,  ..., 2.3408, 0.6073, 1.4446]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7723, 1.2624, 0.8196,  ..., 2.1155, 0.6784, 1.6843]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7783, 1.3553, 0.4751,  ..., 2.0412, 0.0642, 1.7894]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.8865,  1.1013,  0.2454,  ...,  1.7418, -0.2264,  1.4646]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.1849,  0.9042,  1.3882,  ...,  2.5658, -0.4193,  1.0905]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.2369, 0.8981, 1.3165,  ..., 2.1362, 0.1436, 1.1773]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7985, 1.0845, 0.6835,  ..., 1.1056, 0.2461, 1.3905]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8240, 0.9724, 1.0590,  ..., 2.1521, 0.1386, 1.8426]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.2198, 0.6095, 0.3485,  ..., 2.5895, 0.3518, 1.7063]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.6257, 0.6127, 0.4391,  ..., 2.6095, 0.2264, 1.9777]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 0.5976,  1.0942,  0.3841,  ...,  2.4272, -0.1358,  1.2888]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7428, 1.3810, 0.6481,  ..., 2.5798, 0.7127, 0.8711]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.8525, 0.6410, 0.8851,  ..., 2.1037, 0.4725, 1.4233]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.9490,  0.7314,  1.1405,  ...,  2.0898, -0.0362,  1.3102]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.2435, 0.1196, 0.5704,  ..., 2.9347, 0.5549, 1.6675]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4232, 0.3140, 0.4943,  ..., 2.6548, 0.7023, 1.3800]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0614, 0.8351, 1.3822,  ..., 2.4861, 0.0247, 0.9267]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.9102,  1.8726,  0.7918,  ...,  1.8794, -0.1567,  1.2348]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.2924,  1.1380,  0.6505,  ...,  1.9559, -0.2359,  1.0854]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.0407,  0.8604,  0.5258,  ...,  1.8118, -0.1604,  1.4096]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.5761, 0.4353, 1.6724,  ..., 2.7700, 0.8472, 1.3123]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.4959, 0.8235, 0.9422,  ..., 3.1512, 0.9107, 1.0810]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.0337, 0.2129, 0.7851,  ..., 2.4406, 0.6771, 1.3257]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1781, 1.0745, 0.9462,  ..., 2.3144, 0.2597, 1.2874]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.6449,  1.2638,  0.5177,  ...,  2.8200, -0.0736,  0.8353]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.1882,  0.3993,  0.5401,  ...,  2.3976, -0.2114,  1.4132]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.2367, 0.2644, 0.6332,  ..., 1.7972, 0.8739, 1.6171]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.7595, 0.8569, 0.4762,  ..., 2.1324, 0.6500, 1.5170]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.1328, 1.1690, 0.0420,  ..., 2.5087, 0.3553, 2.0753]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[1.1191, 0.8801, 0.1256,  ..., 2.0626, 0.0071, 2.0042]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.3540, 0.8287, 1.1555,  ..., 2.1103, 0.3490, 1.5352]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[2.1110, 0.6875, 1.4090,  ..., 2.2747, 0.2487, 1.7183]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 2.1723,  0.2177,  0.8607,  ...,  2.2671, -0.0179,  1.2439]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[ 1.8762,  1.0761, -0.2736,  ...,  2.0583,  0.5395,  1.5843]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)]\n"
          ]
        }
      ],
      "source": [
        "# TODO: Just taking the last layer for fine grain acoustic tokens and middle layer for semantic tokens, perhaps this should be tuned?\n",
        "src_fine_grain_tokens = src_hidden_states[-1]\n",
        "src_semantic_tokens = src_hidden_states[int(src_hidden_states.size(dim = 0) / 2)]\n",
        "\n",
        "# TODO: Is just concatenating the fine grain tokens and semantic tokens acceptable?\n",
        "# Ideally the dimension here needs to match with the eventual encoded dimensions\n",
        "src_hybrid_tokens = torch.cat((src_fine_grain_tokens, src_semantic_tokens), dim=1)\n",
        "\n",
        "# TODO: This should come from encodec, just putting as an example here\n",
        "tgt_fine_grain_tokens = tgt_hidden_states[-1]\n",
        "tgt_semantic_tokens = tgt_hidden_states[int(tgt_hidden_states.size(dim = 0) / 2)]\n",
        "tgt_hybrid_tokens = torch.cat((tgt_fine_grain_tokens, tgt_semantic_tokens), dim=1)\n",
        "\n",
        "# TODO: What is the appropriate starting token?\n",
        "previously_generated_token = torch.zeros([1, 2 * d_model])\n",
        "\n",
        "generated_tokens = []\n",
        "\n",
        "for index, tgt_hybrid_token in enumerate(tgt_hybrid_tokens):\n",
        "  print(\"Generating token: \" + str(index) + \"/\" + str(seq_length))\n",
        "\n",
        "  generated_token = transformer_decoder(tgt = previously_generated_token, memory = src_hybrid_tokens)\n",
        "  #TODO: Calculate loss between generated_token and tgt_fine_grain_token and then backpropogate once per loop?\n",
        "\n",
        "  generated_tokens.append(generated_token)\n",
        "  previously_generated_token = generated_token\n",
        "\n",
        "print(\"Generated tokens: \" + str(generated_tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUyqhwraRlLu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}